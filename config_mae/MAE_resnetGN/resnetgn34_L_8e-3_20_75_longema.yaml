# Classification config for LatentResNet

wandb:
  project: "vae-test"
  entity: "mingyangd"
  name: null

# Dataset configuration
dataset:
  # Supported: mnist, cifar10, imagenet32, imagenet64, imagenet128, imagenet256
  name: "imagenet256_cache"
  img_shape: [4, 32, 32]

# Model configuration for LatentResNet
# Only simple fields are needed; `arch` is mapped to (block, layers) in code
model:
  num_classes: 1000
  in_channels: 4
  base_channels: 160
  layers: [3, 8, 12, 5]
  dropout_prob: 0.0
  patch_size: 2

# Training parameters
train:
  n_steps: 80000
  total_batch_size: 32768
  ema_dict:
    halflife_kimg: 4000
  save_per_step: 5000
  eval_per_step: 1000
  compile_model: false
  use_bf16: false
  eval_gen_batch_size: 256
  lr_schedule:
    lr: 0.008
    warmup_kimg: 100000
    total_kimg: 100000000
    clip_grad: 1.0
  load_dict:
    run_id: ""
    epoch: ""
    continue_training: false
  lambda_cls: 0.5
  mask_ratio_min: 0.2
  mask_ratio_max: 0.75


# Optimizer settings
optimizer:
  lr: 0.0001
  weight_decay: 0.01

model_type: "mae_resnet_gn"