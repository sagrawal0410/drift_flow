# Classification config for LatentResNet

wandb:
  project: "vae-test"
  entity: "mingyangd"
  name: null

# Dataset configuration
dataset:
  # Supported: mnist, cifar10, imagenet32, imagenet64, imagenet128, imagenet256
  name: "imagenet256_cache"
  img_shape: [4, 32, 32]

# Model configuration for LatentResNet
# Only simple fields are needed; `arch` is mapped to (block, layers) in code
model:
  num_classes: 1000
  in_channels: 4
  base_channels: 128
  layers: [3, 4, 6, 3]
  dropout_prob: 0.0
  patch_size: 2

# Training parameters
train:
  n_steps: 200000
  total_batch_size: 8192
  ema_dict:
    halflife_kimg: 100
  save_per_step: 5000
  eval_per_step: 1000
  compile_model: false
  use_bf16: true
  eval_gen_batch_size: 256
  lr_schedule:
    lr: 0.004
    warmup_kimg: 4000
    total_kimg: 2000000
    clip_grad: 1.0
  load_dict:
    run_id: ""
    epoch: ""
    continue_training: false
  lambda_cls: 0.5
  mask_ratio: 0.5

# Optimizer settings
optimizer:
  lr: 0.0001
  weight_decay: 0.01