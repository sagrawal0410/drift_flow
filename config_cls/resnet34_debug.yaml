# Classification config for LatentResNet

wandb:
  project: "latent_resnet"
  entity: "mit-hair"
  name: null

# Dataset configuration
dataset:
  # Supported: mnist, cifar10, imagenet32, imagenet64, imagenet128, imagenet256
  name: "imagenet256_cache"
  img_shape: [4, 32, 32]

# Model configuration for LatentResNet
# Only simple fields are needed; `arch` is mapped to (block, layers) in code
model:
  layers: [3, 4, 6, 3]
  num_classes: 1000      # 1000 for ImageNet
  in_channels: 4        # 3 for RGB images
  base_channels: 128
  dropout_prob: 0.1

# Training parameters
train:
  n_steps: 200000
  total_batch_size: 16
  ema_dict:
    halflife_kimg: 20
  save_per_step: 10000
  eval_per_step: 1000
  compile_model: false
  use_bf16: true
  eval_gen_batch_size: 16
  lr_schedule:
    lr: 0.001
    warmup_kimg: 4000
    total_kimg: 2000000
    clip_grad: 1.0
  load_dict:
    run_id: ""
    epoch: ""
    continue_training: false

# Optimizer settings
optimizer:
  lr: 0.0001
  weight_decay: 0.01